{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ex5_Code.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvDoG0mAYOOl",
        "cellView": "form",
        "outputId": "6d10edd2-518f-44e8-8777-c22c6ba49618"
      },
      "source": [
        "#@title Choose seed value\n",
        "Seed = 1995 #@param {type:\"integer\"}\n",
        "randomDim = 10 #@param {type:\"integer\"}\n",
        "!pip install cleverhans\n",
        "!rm -rf ./logs/\n",
        "%load_ext tensorboard\n",
        "%matplotlib inline\n",
        "\n",
        "import datetime\n",
        "import numpy as np\n",
        "from numpy.random import Generator, PCG64\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "from cleverhans.tf2.attacks.carlini_wagner_l2 import carlini_wagner_l2\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from IPython.display import clear_output\n",
        "from random import sample\n",
        "\n",
        "tf.random.set_seed(Seed)  # Seeding Tensorflow.\n",
        "np.random.seed(Seed)  # Seeding Numpy.\n",
        "# log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "#tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: cleverhans in /usr/local/lib/python3.7/dist-packages (3.1.0)\n",
            "Requirement already satisfied: pycodestyle in /usr/local/lib/python3.7/dist-packages (from cleverhans) (2.7.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from cleverhans) (1.19.5)\n",
            "Requirement already satisfied: tensorflow-probability in /usr/local/lib/python3.7/dist-packages (from cleverhans) (0.12.1)\n",
            "Requirement already satisfied: mnist~=0.2 in /usr/local/lib/python3.7/dist-packages (from cleverhans) (0.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from cleverhans) (3.2.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from cleverhans) (1.0.1)\n",
            "Requirement already satisfied: nose in /usr/local/lib/python3.7/dist-packages (from cleverhans) (1.3.7)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from cleverhans) (1.4.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability->cleverhans) (1.15.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability->cleverhans) (4.4.2)\n",
            "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability->cleverhans) (0.4.0)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability->cleverhans) (1.3.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability->cleverhans) (0.1.6)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->cleverhans) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->cleverhans) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->cleverhans) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->cleverhans) (2.8.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHJL9aA_Tu0E"
      },
      "source": [
        "# MNIST Dataset - Loading & Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxA4MpybTvnB"
      },
      "source": [
        "num_classes = 10\n",
        "img_rows, img_cols, img_colors = 28, 28, 1  # Greyscale images of 28 X 28.\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
        "X_train = (X_train.astype(np.float32) - 127.5)/127.5\n",
        "X_train = X_train[:,:,:,np.newaxis]\n",
        "X_test = (X_test.astype(np.float32) - 127.5)/127.5\n",
        "X_test = X_test[:,:,:, np.newaxis]\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qqZkO3WZDe_"
      },
      "source": [
        "# GAN Components"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jf4vQN3oam_n"
      },
      "source": [
        "## Generator Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixcU680canjK"
      },
      "source": [
        "# Optimizer\n",
        "adam = keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
        "\n",
        "# Generator\n",
        "generator = keras.Sequential(name=\"MNIST_GAN_GENERATOR\")\n",
        "generator.add(layers.Dense(7*7*128, input_dim=randomDim))\n",
        "generator.add(layers.LeakyReLU(0.2))\n",
        "generator.add(layers.Reshape((7, 7, 128)))\n",
        "generator.add(layers.UpSampling2D(size=(2, 2)))\n",
        "generator.add(layers.Conv2D(64, kernel_size=(5, 5), padding='same'))\n",
        "generator.add(layers.LeakyReLU(0.2))\n",
        "generator.add(layers.UpSampling2D(size=(2, 2)))\n",
        "generator.add(layers.Conv2D(1, kernel_size=(5, 5), padding='same', activation='tanh'))\n",
        "generator.compile(loss='binary_crossentropy', optimizer=adam)\n",
        "\n",
        "generator.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bP17CWjQay2V"
      },
      "source": [
        "## Discriminator Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TK4v_x7oazLd"
      },
      "source": [
        "# Discriminator\n",
        "discriminator = keras.Sequential(name=\"MNIST_GAN_DISCRIMINATOR\")\n",
        "discriminator.add(layers.Conv2D(64, kernel_size=(5, 5), strides=(2, 2), padding='same', input_shape=(28, 28, 1)))\n",
        "discriminator.add(layers.LeakyReLU(0.2))\n",
        "discriminator.add(layers.Dropout(0.3))\n",
        "discriminator.add(layers.Conv2D(128, kernel_size=(5, 5), strides=(2, 2), padding='same'))\n",
        "discriminator.add(layers.LeakyReLU(0.2))\n",
        "discriminator.add(layers.Dropout(0.3))\n",
        "discriminator.add(layers.Flatten())\n",
        "discriminator.add(layers.Dense(1, activation='sigmoid'))\n",
        "discriminator.compile(loss='binary_crossentropy', optimizer=adam)\n",
        "\n",
        "discriminator.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mbChdbPbUnO"
      },
      "source": [
        "## Combined Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Npl4rWLbXG7"
      },
      "source": [
        "# Combined network\n",
        "discriminator.trainable = False\n",
        "ganInput = layers.Input(shape=(randomDim,))\n",
        "x = generator(ganInput)\n",
        "ganOutput = discriminator(x)\n",
        "gan = keras.Model(inputs=ganInput, outputs=ganOutput)\n",
        "gan.compile(loss='binary_crossentropy', optimizer=adam)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nkc-ZPmScCGw"
      },
      "source": [
        "## Graph Plot Functions for GAN Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvrB4mECJoEB"
      },
      "source": [
        "dLosses = []\n",
        "gLosses = []\n",
        "\n",
        "# Plot the loss from each batch\n",
        "def plotLoss():\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    plt.plot(dLosses, label='Discriminitive loss')\n",
        "    plt.plot(gLosses, label='Generative loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# Create a wall of generated MNIST images\n",
        "def plotGeneratedImages(z=None,examples=100, dim=(10, 10), figsize=(10, 10)):\n",
        "    if z is None :\n",
        "      z = np.random.normal(0, 1, size=[examples, randomDim])\n",
        "    generatedImages = generator.predict(z)\n",
        "\n",
        "    plt.figure(figsize=figsize)\n",
        "    for i in range(generatedImages.shape[0]):\n",
        "        plt.subplot(dim[0], dim[1], i+1)\n",
        "        plt.imshow(generatedImages[i].reshape((28,28)), interpolation='nearest', cmap='gray_r')\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwxGV-BBcKoo"
      },
      "source": [
        "## Training The GAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceovIoVvxRLH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71df8a12-eb69-4c1c-9843-adcf978fb6ac"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FO6iqIecJoEI"
      },
      "source": [
        "#@title GAN Training Config\n",
        "\n",
        "gan_batch_size: int = 128  #@param {type:\"integer\"}\n",
        "gan_epochs: int = 100  #@param {type:\"integer\"}\n",
        "Train_gan: bool = False #@param {type:\"boolean\"}\n",
        "\n",
        "def GAN_train(epochs=1, batchSize=128):\n",
        "    batchCount = int(X_train.shape[0] / batchSize)\n",
        "    print('Epochs:', epochs)\n",
        "    print('Batch size:', batchSize)\n",
        "    print('Batches per epoch:', batchCount)\n",
        "\n",
        "    for epoch in range(1, epochs+1):\n",
        "        print('\\n','-'*15, 'Epoch ', epoch, '-'*15)\n",
        "        for batch in range(batchCount):\n",
        "            print(\"\\rBatch number: %d/%d\" % (batch, batchCount), end=\"\")\n",
        "            \n",
        "            # Get a random set of input noise and images\n",
        "            noise = np.random.normal(0, 1, size=[batchSize, randomDim])\n",
        "            imageBatch = X_train[np.random.randint(0, X_train.shape[0], size=batchSize)]\n",
        "\n",
        "            # Generate fake MNIST images\n",
        "            generatedImages = generator.predict(noise)\n",
        "            X = np.concatenate([imageBatch, generatedImages])\n",
        "\n",
        "            # Labels for generated and real data\n",
        "            yDis = np.zeros(2*batchSize)\n",
        "            # One-sided label smoothing - this is done because of the 'sigmoid' output of the discriminator\n",
        "            yDis[:batchSize] = 0.9\n",
        "\n",
        "            # Train discriminator\n",
        "            discriminator.trainable = True\n",
        "            dloss = discriminator.train_on_batch(X, yDis)\n",
        "\n",
        "            # Train generator\n",
        "            noise = np.random.normal(0, 1, size=[batchSize, randomDim])\n",
        "            yGen = np.ones(batchSize)\n",
        "            discriminator.trainable = False\n",
        "            gloss = gan.train_on_batch(noise, yGen)\n",
        "\n",
        "        # Store loss of most recent batch from this epoch\n",
        "        dLosses.append(dloss)\n",
        "        gLosses.append(gloss)\n",
        "\n",
        "        if epoch == 1 or epoch % 5 == 0:\n",
        "            plotGeneratedImages()\n",
        "\n",
        "    # Plot losses from every epoch\n",
        "    plotLoss()\n",
        "\n",
        "if Train_gan:\n",
        "  GAN_train(gan_epochs, gan_batch_size)\n",
        "  gan_path='/content/drive/MyDrive/AdversarialML/Ex5/Saved_model'\n",
        "  model.save(gan_path)\n",
        "  \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwaUEsUoxxSz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3dcc6e2-5818-4be3-d412-cafd8d9cd676"
      },
      "source": [
        "\n",
        "\n",
        "if Train_gan == False:\n",
        "  gan_path='/content/drive/MyDrive/AdversarialML/Ex5/ex5/ex5' # Zvika\n",
        "  # gan_path = '/content/drive/MyDrive/Projects/AdversarialLearningCourse/HWs/AdversarialML/Ex5/ex5'  # Elad\n",
        "  #tf.keras.models.load_model(gan_path)\n",
        "  gan=tf.keras.models.load_model(gan_path)\n",
        "  generator=gan.get_layer(index=1)\n",
        "  discriminator=gan.get_layer(index=2)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijIaXJkFEVzM"
      },
      "source": [
        "# Attack Functions\n",
        "\n",
        "> Below are all available attacks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29qjI9OzqHdD"
      },
      "source": [
        "## FGSM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSLmJNI9qJ4n"
      },
      "source": [
        "@tf.function\n",
        "def FastGradientSignMethod(model, images, labels, epsilon=0.3):\n",
        "    with tf.GradientTape() as grad:\n",
        "        true_label_tensor = labels\n",
        "        input_tensor = images\n",
        "        predicted = model(input_tensor)\n",
        "        adv_loss = keras.losses.categorical_crossentropy(true_label_tensor, predicted)\n",
        "    adv_grads = grad.gradient(adv_loss, input_tensor)\n",
        "\n",
        "    # Finally, the FGSM formula is rather straight forward x`= x + epsilon * sign(loss(x,y))\n",
        "    delta = tf.cast(tf.sign(adv_grads), tf.float32)\n",
        "    \n",
        "    delta = tf.multiply(epsilon, delta)\n",
        "    adv_out = input_tensor + delta\n",
        "    return adv_out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZVzQALQqMtz"
      },
      "source": [
        "## TGSM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jz7ztptdqOls"
      },
      "source": [
        "@tf.function\n",
        "def TargetedGradientSignMethod(model, images, target, epsilon=0.3):\n",
        "    with tf.GradientTape() as grad:\n",
        "        target_label_tensor = target\n",
        "        input_tensor = images\n",
        "        predicted = model(input_tensor)\n",
        "        adv_loss = keras.losses.categorical_crossentropy(target_label_tensor, predicted)\n",
        "    adv_grads = grad.gradient(adv_loss, input_tensor)\n",
        "\n",
        "    # Finally, the TGSM formula is rather straight forward x`= x - epsilon * sign(loss(x,y))\n",
        "    delta = tf.cast(tf.sign(adv_grads), tf.float32)\n",
        "    \n",
        "    delta = tf.multiply(epsilon, delta)\n",
        "    adv_out = input_tensor - delta\n",
        "    return adv_out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RObR0N2YqRRt"
      },
      "source": [
        "## PGD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jF7gVhLZqTVG"
      },
      "source": [
        "@tf.function \n",
        "def PGD_Step(model, images, prev_step, labels, epsilon, iter_eps, min_x, max_x, targeted):\n",
        "    with tf.GradientTape() as grad:\n",
        "        input_tensor = prev_step\n",
        "        if targeted:\n",
        "          target_label = tf.math.abs(tf.math.subtract(tf.math.argmax(labels, axis=1), 5)) # target label =abs(label-5)\n",
        "          target_label_tensor = tf.one_hot(target_label, num_classes)\n",
        "        \n",
        "        else:\n",
        "          target_label_tensor = labels\n",
        "\n",
        "        predicted = model(input_tensor)\n",
        "        adv_loss = keras.losses.categorical_crossentropy(target_label_tensor, predicted)\n",
        "    adv_grads = grad.gradient(adv_loss, input_tensor)\n",
        "\n",
        "\n",
        "\n",
        "    # Perturb the input\n",
        "    if targeted:\n",
        "        adv_out = input_tensor - tf.multiply(iter_eps, tf.cast(tf.sign(adv_grads), tf.float32))\n",
        "    else:\n",
        "        adv_out = input_tensor + tf.multiply(iter_eps, tf.cast(tf.sign(adv_grads), tf.float32))\n",
        "\n",
        "    # Project the perturbation to the epsilon ball (L2 projection)\n",
        "    perturbation = adv_out - images\n",
        "    norm = tf.reduce_sum(tf.square(perturbation), axis=(1,2,3), keepdims=True)\n",
        "    norm = tf.sqrt(tf.maximum(10e-12, norm))\n",
        "    factor = tf.minimum(1.0, tf.divide(epsilon, norm))\n",
        "    adv_out = tf.clip_by_value(images + tf.multiply(perturbation, factor), min_x, max_x)\n",
        "\n",
        "    return adv_out\n",
        "  \n",
        "\n",
        "@tf.function \n",
        "def PGD(model, images, labels, epsilon=0.1, iter_eps = 0.05, iterations=10, min_x=0.0, max_x=1.0, targeted=False):\n",
        "    source = tf.identity(images)\n",
        "    adv_out = images\n",
        "\n",
        "    iteration = tf.constant(0, dtype=tf.int32)\n",
        "    while tf.less(iteration, iterations):\n",
        "        tf.print('Attack iteration:', iteration)\n",
        "        adv_out.assign(PGD_Step(model, source, adv_out, labels, epsilon, iter_eps, min_x, max_x, targeted))\n",
        "        iteration += 1\n",
        "\n",
        "    return adv_out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUJ-fsEJqXDA"
      },
      "source": [
        "## BIM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhiaqQqAEYLZ"
      },
      "source": [
        "@tf.function\n",
        "def BIM_Step(model, images, labels, epsilon, iter_eps, min_x, max_x, targeted):\n",
        "    \n",
        "    with tf.GradientTape() as grad:\n",
        "        input_tensor = images\n",
        "        target_label_tensor = labels\n",
        "        predicted = model(input_tensor)\n",
        "        adv_loss = keras.losses.categorical_crossentropy(target_label_tensor, predicted)\n",
        "    adv_grads = grad.gradient(adv_loss, input_tensor)\n",
        "\n",
        "    # Perturb the input\n",
        "    if targeted:\n",
        "        adv_out = input_tensor - tf.multiply(iter_eps, tf.cast(tf.sign(adv_grads), tf.float32))\n",
        "    else:\n",
        "        adv_out = input_tensor + tf.multiply(iter_eps, tf.cast(tf.sign(adv_grads), tf.float32))\n",
        "        \n",
        "    # Clip the intermdiate adversarial examples in order to ensure they are within\n",
        "    # the valid data range\n",
        "    delta = adv_out - images\n",
        "    delta = tf.clip_by_value(delta, -epsilon, epsilon)\n",
        "    adv_out = images + delta\n",
        "    adv_out = tf.clip_by_value(adv_out, min_x, max_x)\n",
        "\n",
        "    return adv_out\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def BIM(model, images, labels, epsilon=0.1, iter_eps = 0.05, iterations=10, min_x=0.0, max_x=1.0, targeted=False):\n",
        "    \n",
        "    adv_out = images\n",
        "    iteration = tf.constant(0, dtype=tf.int32)\n",
        "    \n",
        "    while tf.less(iteration, iterations):\n",
        "        tf.print('Iteration:', iteration)\n",
        "        # Note the use of 'assign' here instead of the '=' operator. This means, adv_out continues to point to the same\n",
        "        # tensor, the same computation graph node, the same physical portion of GPU memory.\n",
        "        # This is crucial because of the while loop structure. Recall that the 'tf.function' decoration creates a static \n",
        "        # computation graph. The python code is transformed into a graph only once.\n",
        "        # Hence if we make adv_out point to a different graph node we will not be able to compute a valid gradient\n",
        "        adv_out.assign(BIM_Step(model, adv_out, labels, epsilon, iter_eps, min_x, max_x, targeted))\n",
        "        iteration += 1\n",
        "\n",
        "    return adv_out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ImYhfblqcfd"
      },
      "source": [
        "## Attack Choices & Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGHEkn0wqaHa"
      },
      "source": [
        "def commence_attack(model, attack_type, orig_images, true_labels, \n",
        "                    target_labels=None, attack_iters: int=1, \n",
        "                    epsilon: float=0.3, iter_eps: float=0.3):\n",
        "    epsilon = tf.Variable(epsilon, dtype=tf.float32)\n",
        "    iter_eps = tf.Variable(iter_eps)\n",
        "    attack_iters = tf.Variable(attack_iters, dtype=tf.int32)\n",
        "\n",
        "    if attack_type == \"FGSM\":\n",
        "      adv_images = FastGradientSignMethod(model, orig_images, true_labels, \n",
        "                                          epsilon=epsilon).numpy()\n",
        "      \n",
        "    elif attack_type == \"BIM(L_inf)\":\n",
        "      adv_images = BIM(model, orig_images, true_labels, epsilon=epsilon,\n",
        "                       iter_eps=iter_eps, targeted=False, \n",
        "                       iterations=attack_iters).numpy()\n",
        "\n",
        "    elif attack_type == \"PGD(L_2)\":\n",
        "      adv_images = PGD(model, orig_images, true_labels, epsilon=epsilon,\n",
        "                       iter_eps=iter_eps, targeted=False, \n",
        "                       iterations=attack_iters).numpy()\n",
        "      \n",
        "    elif attack_type == \"PGD_target(L_2)\":\n",
        "      adv_images = PGD(model, orig_images, true_labels, epsilon=epsilon,\n",
        "                       iter_eps=iter_eps, targeted=True, # if  targeted=True , then target labels:=abs(true_labels-5)\n",
        "                       iterations=attack_iters).numpy()\n",
        "      \n",
        "    elif attack_type == \"Carlini & Wagner(L_2)\":\n",
        "      adv_images = carlini_wagner_l2(model, orig_images.numpy(), targeted=False, \n",
        "                                     learning_rate=epsilon,\n",
        "                                     max_iterations=attack_iters.numpy(),\n",
        "                                     clip_min=-1.0)\n",
        "      \n",
        "    return adv_images\n",
        "\n",
        "def TestAttack(model, adv_images, orig_images, true_labels, target_labels=None, targeted=False):\n",
        "    ''' \n",
        "    A simple utility funcion for evaluating the success of an attack\n",
        "    '''\n",
        "    score = model.evaluate(adv_images, true_labels, verbose=0)\n",
        "    print('Test loss: {:.2f}'.format(score[0]))\n",
        "    print('Successfully moved out of source class: {:.2f}'.format( 1 - score[1]))\n",
        "\n",
        "    \n",
        "    if targeted:  # if targeted is True\n",
        "        score = model.evaluate(adv_images, target_labels, verbose=0)\n",
        "        print('Test loss: {:.2f}'.format(score[0]))\n",
        "        print('Successfully perturbed to target class: {:.2f}'.format(score[1]))\n",
        "\n",
        "    \n",
        "    dist = np.mean(np.sqrt(np.mean(np.square(adv_images - orig_images), axis=(1,2,3))))\n",
        "    print('Mean perturbation distance: {:.2f}'.format(dist))\n",
        "\n",
        "def perform_all_attacks(model, target_labels,samples=100,save=False):\n",
        "  attack_type_array = [\"FGSM\", \"BIM(L_inf)\",\"Carlini & Wagner(L_2)\", \"PGD(L_2)\",\"PGD_target(L_2)\"]\n",
        "  \n",
        "  sample_index=sample(range(len(X_test)),samples)\n",
        "  adv_images_all=np.zeros([samples*len(attack_type_array),28,28,1])\n",
        "  \n",
        "\n",
        "  \n",
        "  y_test_sample=y_test[sample_index].copy()\n",
        "  X_test_sample=X_test[sample_index].copy()\n",
        "  test_images_tensor = tf.Variable(X_test_sample, dtype=tf.float32)\n",
        "  test_labels_tensor = tf.Variable(y_test_sample, dtype=tf.float32)\n",
        "\n",
        "  for i,attack_type in enumerate(attack_type_array):\n",
        "    # Performing the attack.\n",
        "  \n",
        "    \n",
        "    is_attack_targeted: bool = attack_type == \"PGD_target(L_2)\"\n",
        "    print('\\n', attack_type + \" method\",'\\n')\n",
        "    adv_images = commence_attack(model, attack_type, test_images_tensor, \n",
        "                                 test_labels_tensor,\n",
        "                                 target_labels=target_labels,\n",
        "                                 attack_iters=attack_iters, epsilon=epsilon, \n",
        "                                 iter_eps=iter_eps)\n",
        "\n",
        "    print(adv_images.shape)\n",
        "\n",
        "    adv_images_all[i*samples:i*samples+samples]=adv_images\n",
        "    print(adv_images_all.shape)\n",
        "\n",
        "\n",
        "    # Evaluate the performance of the attack.\n",
        "    TestAttack(model, adv_images, X_test[sample_index], y_test[sample_index], \n",
        "               targeted=is_attack_targeted)\n",
        "  if save:\n",
        "    return adv_images_all,X_test_sample,y_test_sample\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQYiK-E_DlB4"
      },
      "source": [
        "# Attack Config\n",
        "\n",
        "> Shared parameters between all attacks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-PEBT_GDj7O",
        "cellView": "form"
      },
      "source": [
        "#@title Attack Configuration\n",
        "epsilon = 0.1 #@param {type:\"number\"}\n",
        "iter_eps = 0.05 #@param {type:\"number\"}\n",
        "#attack_type = \"FGSM\" #@param [\"FGSM\", \"BIM(L_inf)\", \"PGD(L_2)\",'PGD_target(L_2)']\n",
        "attack_iters = 4 #@param {type:\"integer\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrf0TCCteADH"
      },
      "source": [
        "#Classifiers For Investigation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzptOx4aeDS_"
      },
      "source": [
        "def CNN_mnist_model(img_rows, img_cols, img_colors, num_classes, learning_rate,\n",
        "                    name = \"CNN\"):\n",
        "    activation = 'relu'\n",
        "    model = keras.Sequential(name=name)\n",
        "    model.add(layers.Conv2D(8, kernel_size=(3, 3), input_shape=(img_rows, img_cols, img_colors), activation=activation))\n",
        "    model.add(layers.Conv2D(8, (3, 3), activation=activation))\n",
        "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(layers.Dropout(0.25))\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(128, activation=activation))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "    model.add(layers.Dense(num_classes))\n",
        "    model.add(layers.Activation('softmax', name='softmax'))\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                optimizer=keras.optimizers.Adadelta(learning_rate),\n",
        "                metrics=[keras.metrics.CategoricalAccuracy()])\n",
        "    return model\n",
        "\n",
        "\n",
        "def train_model(model, max_epochs: int, train_images, train_labels, test_images, \n",
        "                test_labels, batch_size, callbacks_list, verbose=1):\n",
        "    history = model.fit(train_images, train_labels,\n",
        "        batch_size=batch_size,\n",
        "        epochs=max_epochs,\n",
        "        verbose=verbose,\n",
        "        validation_data=(test_images, test_labels),\n",
        "        callbacks=callbacks_list)\n",
        "    return history\n",
        "\n",
        "def lr_scheduler(epoch):\n",
        "  return learning_rate * (0.5 ** (epoch // lr_drop))\n",
        "reduce_lr = keras.callbacks.LearningRateScheduler(lr_scheduler)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IO-o8g0ethM"
      },
      "source": [
        "# Training The Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gT2Rn-8c8zED",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "565a4d28-c643-4126-e592-dde33b3dd94e"
      },
      "source": [
        "#@title Select The Classifier to Attack and Hyperparameters\n",
        "selected_model = \"CNN from Lecture 2\" #@param [\"CNN from Lecture 2\", \"NN from Ex 1\"]\n",
        "batch_size = 128 #@param {type:\"integer\"}\n",
        "max_epochs = 12 #@param {type:\"integer\"}\n",
        "learning_rate = 0.1 #@param {type:\"number\"}\n",
        "lr_decay = 1e-6 #@param {type:\"number\"}\n",
        "lr_drop = 6 #@param {type:\"number\"}\n",
        "\n",
        "\n",
        "classifier = CNN_mnist_model(img_rows, img_cols, img_colors, \n",
        "                             num_classes, learning_rate)\n",
        "print('Architecture of Classifier:')\n",
        "classifier.summary()\n",
        "\n",
        "callbacks_list = [reduce_lr]\n",
        "print(\"Training the teacher model for all 10 classes of MNIST\")\n",
        "classifier_history = train_model(classifier, max_epochs, X_train, \n",
        "                                 y_train, X_test, y_test, \n",
        "                                 batch_size, callbacks_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Architecture of Classifier:\n",
            "Model: \"CNN\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_4 (Conv2D)            (None, 26, 26, 8)         80        \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 24, 24, 8)         584       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 8)         0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 12, 12, 8)         0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 1152)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 128)               147584    \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                1290      \n",
            "_________________________________________________________________\n",
            "softmax (Activation)         (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 149,538\n",
            "Trainable params: 149,538\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Training the teacher model for all 10 classes of MNIST\n",
            "Epoch 1/12\n",
            "469/469 [==============================] - 33s 69ms/step - loss: 0.9829 - categorical_accuracy: 0.6878 - val_loss: 0.2801 - val_categorical_accuracy: 0.9227\n",
            "Epoch 2/12\n",
            "469/469 [==============================] - 32s 69ms/step - loss: 0.4097 - categorical_accuracy: 0.8756 - val_loss: 0.2023 - val_categorical_accuracy: 0.9417\n",
            "Epoch 3/12\n",
            "469/469 [==============================] - 32s 68ms/step - loss: 0.3303 - categorical_accuracy: 0.8990 - val_loss: 0.1655 - val_categorical_accuracy: 0.9522\n",
            "Epoch 4/12\n",
            "469/469 [==============================] - 32s 69ms/step - loss: 0.2811 - categorical_accuracy: 0.9140 - val_loss: 0.1402 - val_categorical_accuracy: 0.9589\n",
            "Epoch 5/12\n",
            "469/469 [==============================] - 32s 68ms/step - loss: 0.2474 - categorical_accuracy: 0.9252 - val_loss: 0.1256 - val_categorical_accuracy: 0.9625\n",
            "Epoch 6/12\n",
            "469/469 [==============================] - 32s 68ms/step - loss: 0.2231 - categorical_accuracy: 0.9317 - val_loss: 0.1126 - val_categorical_accuracy: 0.9656\n",
            "Epoch 7/12\n",
            "469/469 [==============================] - 32s 68ms/step - loss: 0.2114 - categorical_accuracy: 0.9370 - val_loss: 0.1054 - val_categorical_accuracy: 0.9688\n",
            "Epoch 8/12\n",
            "469/469 [==============================] - 32s 69ms/step - loss: 0.1999 - categorical_accuracy: 0.9396 - val_loss: 0.1020 - val_categorical_accuracy: 0.9693\n",
            "Epoch 9/12\n",
            "469/469 [==============================] - 32s 68ms/step - loss: 0.1934 - categorical_accuracy: 0.9414 - val_loss: 0.0973 - val_categorical_accuracy: 0.9712\n",
            "Epoch 10/12\n",
            "469/469 [==============================] - 32s 68ms/step - loss: 0.1883 - categorical_accuracy: 0.9426 - val_loss: 0.0940 - val_categorical_accuracy: 0.9723\n",
            "Epoch 11/12\n",
            "469/469 [==============================] - 32s 69ms/step - loss: 0.1823 - categorical_accuracy: 0.9453 - val_loss: 0.0900 - val_categorical_accuracy: 0.9726\n",
            "Epoch 12/12\n",
            "469/469 [==============================] - 32s 69ms/step - loss: 0.1758 - categorical_accuracy: 0.9459 - val_loss: 0.0870 - val_categorical_accuracy: 0.9739\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fk0O19xvAcFt"
      },
      "source": [
        "# Gradient-Descent for GAN-Detector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGhpMW4ai70C"
      },
      "source": [
        "@tf.function \n",
        "def find_optimal_z_step(generator_model, x: tf.Tensor, z: tf.Variable, \n",
        "                        learning_rate: tf.constant):\n",
        "\n",
        "    with tf.GradientTape() as grad:\n",
        "        input_tensor = z\n",
        "        predicted = generator_model(input_tensor)\n",
        "        z_loss = keras.losses.MSE(tf.reshape(x, [x.shape[0], -1]), \n",
        "                                  tf.reshape(predicted, [predicted.shape[0], -1]))\n",
        "    z_grads = grad.gradient(z_loss, input_tensor)\n",
        "\n",
        "    z_out = input_tensor - tf.multiply(learning_rate, tf.cast(z_grads, tf.float32))\n",
        "    return z_out\n",
        "\n",
        "\n",
        "z = tf.Variable(np.ones((2, randomDim)), name = 'z', dtype = tf.float32)\n",
        "\n",
        "@tf.function\n",
        "def find_optimal_z(generator_model, x: tf.Tensor, z: tf.Variable, \n",
        "                   epochs_num: tf.constant, learning_rate: tf.constant):\n",
        "    z_minimal = z\n",
        "    iteration = tf.constant(0, dtype=tf.int32)\n",
        "     \n",
        "    \n",
        "    while tf.less(iteration, epochs_num):\n",
        "        #tf.print('GD iteration:', iteration)\n",
        "        z_minimal.assign(find_optimal_z_step(generator_model, x, z_minimal, \n",
        "                                             learning_rate))\n",
        "\n",
        "        iteration += 1\n",
        "        if tf.math.floormod(iteration,25)==0:\n",
        "          learning_rate_i=learning_rate/tf.constant(2, dtype=tf.float32)\n",
        "\n",
        "    return z_minimal"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6ecS1Jkgbww"
      },
      "source": [
        "## Commencing All Attacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EWHHYBJAS6e"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Vugt9ARITzM",
        "outputId": "b7db1bf8-e4f5-4599-bb0d-d668b7fbdfeb"
      },
      "source": [
        "adv_images_all, X_test_sample, y_test_sample = perform_all_attacks(classifier, None, samples=100, save=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " FGSM method \n",
            "\n",
            "(100, 28, 28, 1)\n",
            "(500, 28, 28, 1)\n",
            "Test loss: 0.19\n",
            "Successfully moved out of source class: 0.06\n",
            "Mean perturbation distance: 0.10\n",
            "\n",
            " BIM(L_inf) method \n",
            "\n",
            "Iteration: 0\n",
            "Iteration: 1\n",
            "Iteration: 2\n",
            "Iteration: 3\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function BIM at 0x7f358241f200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "(100, 28, 28, 1)\n",
            "(500, 28, 28, 1)\n",
            "Test loss: 3.39\n",
            "Successfully moved out of source class: 0.94\n",
            "Mean perturbation distance: 0.97\n",
            "\n",
            " Carlini & Wagner(L_2) method \n",
            "\n",
            "(100, 28, 28, 1)\n",
            "(500, 28, 28, 1)\n",
            "Test loss: 3.04\n",
            "Successfully moved out of source class: 0.77\n",
            "Mean perturbation distance: 0.98\n",
            "\n",
            " PGD(L_2) method \n",
            "\n",
            "Attack iteration: 0\n",
            "Attack iteration: 1\n",
            "Attack iteration: 2\n",
            "Attack iteration: 3\n",
            "(100, 28, 28, 1)\n",
            "(500, 28, 28, 1)\n",
            "Test loss: 3.46\n",
            "Successfully moved out of source class: 0.95\n",
            "Mean perturbation distance: 0.97\n",
            "\n",
            " PGD_target(L_2) method \n",
            "\n",
            "Attack iteration: 0\n",
            "Attack iteration: 1\n",
            "Attack iteration: 2\n",
            "Attack iteration: 3\n",
            "(100, 28, 28, 1)\n",
            "(500, 28, 28, 1)\n",
            "Test loss: 3.40\n",
            "Successfully moved out of source class: 0.95\n",
            "Test loss: 0.00\n",
            "Successfully perturbed to target class: 0.00\n",
            "Mean perturbation distance: 0.97\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuaQKWgBIMdJ"
      },
      "source": [
        "#learning_rate_z=tf.constant(0.2) - decreases by half evry 25 epochs\n",
        "\n",
        "z = np.random.normal(0, 1, size=[len(X_test_sample), randomDim])\n",
        "z = tf.Variable(z, name = 'z', dtype = tf.float32)\n",
        "\n",
        "\n",
        "x_gan = tf.Variable(X_test_sample[:,:,:,0], dtype=tf.float32)\n",
        "z = find_optimal_z(generator, x_gan, z, epochs_num=tf.constant(200), learning_rate=tf.constant(0.2))\n",
        "loss_z=np.linalg.norm(generator(z)[:,:,:,0] - x_gan, axis=(1, 2))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6zVDTos40iA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "080c760e-8a2a-46ad-ceb6-504d7891ae99"
      },
      "source": [
        "\n",
        "\n",
        "epsilon_z=20\n",
        "print(\"% Correctly identified by the detector – that is ‖x -G(z*)‖≥ϵ\", 100*np.mean(loss_z>epsilon_z))\n",
        "\n",
        "index=np.where(loss_z<epsilon_z)[0]\n",
        "attack_type_array = [\"FGSM\", \"BIM(L_inf)\", \"PGD(L_2)\", \"PGD_target(L_2)\" ,\"Carlini & Wagner(L_2)\"]\n",
        "for i,attack_type in enumerate(attack_type_array):\n",
        "  print('\\n', attack_type + \" method\",'\\n')\n",
        "  predict_true=classifier.predict_classes(adv_images_all[i*100:i*100+100])==np.argmax(y_test_sample,axis=1)\n",
        "\n",
        "  predict_z_true=np.linalg.norm(generator(z)[:,:,:,0] - adv_images_all[i*100:i*100+100][:,:,:,0], axis=(1, 2))>epsilon_z\n",
        "\n",
        "  print(\"Correctly classified to the original class label %\",sum(predict_z_true | predict_true))\n",
        "  print(\"Correctly identified by the detector – that is ‖x -G(z*)‖≥ϵ  %\", 100*np.mean(predict_z_true))\n",
        "  print(\"% Wrongly classified\", 100-sum(predict_z_true | predict_true))\n",
        "\n",
        "\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "% Correctly identified by the detector – that is ‖x -G(z*)‖≥ϵ 9.0\n",
            "\n",
            " FGSM method \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Correctly classified to the original class label % 95\n",
            "Correctly identified by the detector – that is ‖x -G(z*)‖≥ϵ  % 9.0\n",
            "% Wrongly classified 5\n",
            "\n",
            " BIM(L_inf) method \n",
            "\n",
            "Correctly classified to the original class label % 100\n",
            "Correctly identified by the detector – that is ‖x -G(z*)‖≥ϵ  % 100.0\n",
            "% Wrongly classified 0\n",
            "\n",
            " PGD(L_2) method \n",
            "\n",
            "Correctly classified to the original class label % 100\n",
            "Correctly identified by the detector – that is ‖x -G(z*)‖≥ϵ  % 100.0\n",
            "% Wrongly classified 0\n",
            "\n",
            " PGD_target(L_2) method \n",
            "\n",
            "Correctly classified to the original class label % 100\n",
            "Correctly identified by the detector – that is ‖x -G(z*)‖≥ϵ  % 100.0\n",
            "% Wrongly classified 0\n",
            "\n",
            " Carlini & Wagner(L_2) method \n",
            "\n",
            "Correctly classified to the original class label % 100\n",
            "Correctly identified by the detector – that is ‖x -G(z*)‖≥ϵ  % 100.0\n",
            "% Wrongly classified 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFMMeo5toS3l"
      },
      "source": [
        "index=sample(range(len(X_test)),400)\n",
        "X_test_400=X_test[index]\n",
        "y_test_400=y_test[index]\n",
        "#learning_rate_z=tf.constant(0.2) - decreases by half evry 25 epochs\n",
        "\n",
        "z = np.random.normal(0, 1, size=[len(X_test_400), randomDim])\n",
        "z = tf.Variable(z, name = 'z', dtype = tf.float32)\n",
        "\n",
        "\n",
        "x_gan = tf.Variable(X_test_400[:,:,:,0], dtype=tf.float32)\n",
        "z = find_optimal_z(generator, x_gan, z, epochs_num=tf.constant(200), learning_rate=tf.constant(0.2))\n",
        "loss_z=np.linalg.norm(generator(z)[:,:,:,0] - x_gan, axis=(1, 2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gE29vv3UhGg5"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xG2c-c5dc1p",
        "outputId": "07356e8c-ef21-416a-f26b-ca420f78256d"
      },
      "source": [
        "predict_z_true=np.linalg.norm(generator(z)[:,:,:,0] - X_test_400[:,:,:,0], axis=(1, 2))>epsilon_z\n",
        "print(\"The False Positive detection rate: \",np.round(np.mean(predict_z_true)*100,2))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The False Positive detection rate:  6.25\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}